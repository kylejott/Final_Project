---
title: '**The Finnish Top 0.4 Percent**: An Exploration of Top Tax Shares in Finland from 2009 to 2013'
author: "Kyle Ott and Cornelius Schneider"
date: "14 November 2014"
output:
  pdf_document:
    number_sections: yes
    toc: yes
bibliography:
- main1.bib
- packages1.bib
---
\pagebreak
```{r, include=FALSE}
pkgs <- c('httr', 'dplyr', 'XML', 'ggplot2', 'stringr', 'car', 'devtools', 'rsdmx', 'stargazer', 'knitr', 'tidyr', 'reshape2', 'sandwich', 'lmtest', 'plm', 'Zelig' )
repmis::LoadandCite(pkgs, file = 'packages1.bib')

# set your working directory here
setwd("/Users/Kyle/Dropbox/!Fall_2014/Collab_Data/Final_Project/")

##################################
# Final Assignment: Data Science Course
# Kyle Ott & Cornelius Schneider
# December 12, 2014
##################################

# Load packages
library(httr)
library(dplyr)
library(XML)
library(ggplot2)
library(stringr)
library(car)
library(devtools)
library(rsdmx)
library(stargazer)
library(knitr)
library(tidyr)
library(reshape2)
library(sandwich)
library(lmtest)
library(plm)
library(Zelig)

#################
# Our Unique, Tidy, Open, Reproducible Data 
#################

## this part is scraping from the newspaper website for the years 2009 to 2013
```

```{r, include=FALSE, cache=TRUE}
# 2013 data
tables2013 = data.frame()

for (i in 1:30){

# URL with the ta table
URL_temp2013 <- paste0('http://www.taloussanomat.fi/verotiedot/2013/suurituloisimmat/?n=', i)
if (i==1) { tables2013 <- URL_temp2013 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
            tables2013 <- tables2013[[1]] }
else if (i!=1){

  # Gather content and parse all tables #
table_temp2013 <- URL_temp2013 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()

# Identify correct table
# names(table) # the table does not have an ID

# select first table with taxData
tables_df_temp2013 <- table_temp2013[[1]]

tables2013 <- rbind(tables2013, tables_df_temp2013)

}
#end loop
}
tables2013$year <- 2013

# 2012 data
tables2012 = data.frame()

for (i in 1:30){
  
  # URL with the medals table
  URL_temp2012 <- paste0('http://www.taloussanomat.fi/verotiedot/2012/suurituloisimmat/?n=', i)
  if (i==1) { tables2012 <- URL_temp2012 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
              tables2012 <- tables2012[[1]] }
  else if (i!=1){
    #### Gather content and parse all tables ####
    table_temp2012 <- URL_temp2012 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
    
    # Identify correct table
    # names(table) # the table does not have an ID
    
    # select first table with taxData
    tables_df_temp2012 <- table_temp2012[[1]]
    
    tables2012 <- rbind(tables2012, tables_df_temp2012)
  }
  ##end loop
}

tables2012$year <- 2012


## 2011 data
tables2011 = data.frame()

#note that for some years they don't have complete obs (15,000), which is why the loop is only up to 28 for the following year
for (i in 1:28){
  
  # URL with the medals table
  URL_temp2011 <- paste0('http://www.taloussanomat.fi/verotiedot/2011/suurituloisimmat/?n=', i)
  if (i==1) { tables2011 <- URL_temp2011 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
              tables2011 <- tables2011[[1]] }
  else if (i!=1){
    #### Gather content and parse all tables ####
    table_temp2011 <- URL_temp2011 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
    
    # Identify correct table
    # names(table) # the table does not have an ID
    
    # select first table with taxData
    tables_df_temp2011 <- table_temp2011[[1]]
    
    tables2011 <- rbind(tables2011, tables_df_temp2011)
  }
  #end loop
}

tables2011$year <- 2011

# 2010 data
tables2010 = data.frame()

for (i in 1:29){
  
  # URL with the medals table
  URL_temp2010 <- paste0('http://www.taloussanomat.fi/verotiedot/2010/suurituloisimmat/?n=', i)
  if (i==1) { tables2010 <- URL_temp2010 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
              tables2010 <- tables2010[[1]] }
  else if (i!=1){
    #### Gather content and parse all tables ####
    table_temp2010 <- URL_temp2010 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
        
    # select first table with taxData
    tables_df_temp2010 <- table_temp2010[[1]]
    
    tables2010 <- rbind(tables2010, tables_df_temp2010)
  }
  ##end loop
}

tables2010$year <- 2010

## 2009 data
tables2009 = data.frame()

for (i in 1:25){
  
  # URL with the medals table
  URL_temp2009 <- paste0('http://www.taloussanomat.fi/verotiedot/2009/suurituloisimmat/?n=', i)
  if (i==1) { tables2009 <- URL_temp2009 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
              tables2009 <- tables2009[[1]] }
  else if (i!=1){
    #### Gather content and parse all tables ####
    table_temp2009 <- URL_temp2009 %>% GET() %>% content(as = 'parsed') %>% readHTMLTable()
    
    # select first table with taxData
    tables_df_temp2009 <- table_temp2009[[1]]
    
    tables2009 <- rbind(tables2009, tables_df_temp2009)
  }
  ##end loop
}

tables2009$year <- 2009

#appending scraped tables
all <- rbind(tables2009, tables2010, tables2011, tables2012, tables2013)

save(all, file = "/Users/Kyle/Dropbox/!Fall_2014/Collab_Data/A3_Ott_Schneider/all.RData")


```

```{r, include=FALSE}
load("/Users/Kyle/Dropbox/!Fall_2014/Collab_Data/A3_Ott_Schneider/all.RData")

class(all$year)

#changing the titles to english
all <- plyr::rename(x = all,
                           replace = c("Nimi" = "name",
                                       "Tulot yht" = "total_inc",
                                       "Verot" = "taxes_paid",
                                       "Suhde" = "ratio"
                                       ))
str(all)

#cleaning ratio
all$ratio2 <- str_sub(all$ratio, 1, 2)
summary(all$ratio2)
all$ratio3 <- as.numeric(all$ratio2, length=2)
summary(all$ratio3)

#cleaning taxes_paid
sub(' â¬ $', '',all$taxes_paid)
all$taxes_paid2 <- sub(' â¬$', '',all$taxes_paid)
all$taxes_paid3 <- str_trim(all$taxes_paid2)
all$taxes_paid4 <-sub(' ', '',all$taxes_paid3)
all$taxes_paid5 <-sub(' ', '',all$taxes_paid4)
all$taxes_paid6 <- as.numeric(all$taxes_paid5, length=9)
summary(all$taxes_paid6)

#cleaning total_inc
all$total_inc2 <- sub(' â¬$', '',all$total_inc)
all$total_inc3 <- str_trim(all$total_inc2)
all$total_inc4 <-sub(' ', '',all$total_inc3)
all$total_inc5 <-sub(' ', '',all$total_inc4)
all$total_inc6 <- as.numeric(all$total_inc5, length=13)
summary(all$total_inc6)

#dropping name and keeping rank in given year
all$name2 <- str_sub(all$name, 1, 5)
all$name3 <- sub('\\. ..$', '',all$name2)
all$name4 <- sub('\\. .$', '',all$name3)
all$name5 <- sub('\\. $', '',all$name4)
all$name6 <- sub('\\.$', '',all$name5)
all$name7 <- as.numeric(all$name6, length=5)
summary(all$name7)

#dropping name and keeping rank in given year
all$justname <- str_sub(all$name)
all$justname <- sub('^.*\\. ', '',all$name)

clean <- all[, (colnames(all) %in% c("justname", "name7", "total_inc6", "taxes_paid6", "ratio3", "year"))]
str(clean)
clean <- plyr::rename(x = clean,
                             replace = c("total_inc6" = "total_inc",
                                         "taxes_paid6" = "taxes_paid",
                                         "name7" = "rank",
                                         "ratio3" = "ratio"
                             ))
# add 1 to taxes paid if it is zero to avoid problems
clean$taxes_paid <- replace(clean$taxes_paid,clean$taxes_paid<=1, 1)
save(clean, file = "/Users/Kyle/Dropbox/!Fall_2014/Collab_Data/Final_Project/clean.RData")

```

#Introduction

#Literature Review

#Dataset

#Methodology

#Results

```{r, inlcude=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
load("cleaned.RData")
M1 <- lm(log(avg_inc) ~ log(net_of_tax), data = cleaned, na.action = NULL)
# we have strong autocorr, so we use newey-west SE's
M1a <- coeftest(M1,vcov=NeweyWest)
M2 <- lm(log(avg_inc) ~ log(net_of_tax) + year,data = cleaned, na.action = NULL)
# Create cleaner covariate labels
labels <- c('Elasticity', 'Time Trend')
```

```{r, results='asis', echo=FALSE, error=FALSE, warning=FALSE}
stargazer::stargazer(M1a, M2, covariate.labels = labels,
                     model.names = FALSE,
                     dep.var.labels.include = FALSE,
                     title = 'Time Series Elasticities',
                     type = 'latex', header = FALSE)
```


#Discussion

#Conclusion

#References
